#!/usr/bin/env python3
"""
Adobeè£½å“ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒªãƒªãƒ¼ã‚¹è¿½è·¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
"""

import json
import re
from datetime import datetime, timedelta
from pathlib import Path
import subprocess
import hashlib

# è¨­å®š
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
WORKSPACE = PROJECT_ROOT.parent / ".openclaw" / "workspace"
TRACKING_FILE = WORKSPACE / "memory" / "adobe-tracking.json"
LAST_CHECK_FILE = WORKSPACE / "memory" / "last-adobe-check.txt"

# ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ï¼ˆURLã‚’æœ€æ–°ã®ã‚‚ã®ã«æ›´æ–°ï¼‰
NEWS_SOURCES = {
    "photoshop_release": {
        "name": "Photoshop Release Notes",
        "url": "https://helpx.adobe.com/photoshop/whats-new.html",
        "type": "release_notes"
    },
    "illustrator_release": {
        "name": "Illustrator Release Notes",
        "url": "https://helpx.adobe.com/illustrator/whats-new.html",
        "type": "release_notes"
    },
    "premiere_release": {
        "name": "Premiere Pro Release Notes",
        "url": "https://helpx.adobe.com/premiere-pro/whats-new.html",
        "type": "release_notes"
    },
    "lightroom_release": {
        "name": "Lightroom Release Notes",
        "url": "https://helpx.adobe.com/lightroom/whats-new.html",
        "type": "release_notes"
    },
    "aftereffects_release": {
        "name": "After Effects Release Notes",
        "url": "https://helpx.adobe.com/after-effects/whats-new.html",
        "type": "release_notes"
    },
    "adobe_blog": {
        "name": "Adobe Blog",
        "url": "https://blog.adobe.com/",
        "type": "blog"
    }
}

def load_tracking_data():
    """è¿½è·¡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    if TRACKING_FILE.exists():
        with open(TRACKING_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_tracking_data(data):
    """è¿½è·¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    TRACKING_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(TRACKING_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_last_check():
    """æœ€çµ‚ãƒã‚§ãƒƒã‚¯æ™‚åˆ»ã‚’èª­ã¿è¾¼ã‚€"""
    if LAST_CHECK_FILE.exists():
        with open(LAST_CHECK_FILE, 'r') as f:
            return datetime.fromisoformat(f.read().strip())
    return datetime.now() - timedelta(days=30)

def save_last_check(check_time):
    """æœ€çµ‚ãƒã‚§ãƒƒã‚¯æ™‚åˆ»ã‚’ä¿å­˜"""
    LAST_CHECK_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(LAST_CHECK_FILE, 'w') as f:
        f.write(check_time.isoformat())

def generate_content_hash(content):
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ"""
    return hashlib.md5(content.encode('utf-8')).hexdigest()

def check_url_changes(source_key, url):
    """URLã®å¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        result = subprocess.run(
            ['curl', '-s', '-L', url],
            capture_output=True,
            text=True,
            timeout=15
        )

        if result.returncode == 0:
            # ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‹ã‚‰æ—¥ä»˜æƒ…å ±ã‚’æŠ½å‡º
            content = result.stdout
            content_hash = generate_content_hash(content[:10000])  # æœ€åˆã®10KBã‚’ãƒãƒƒã‚·ãƒ¥åŒ–

            tracking_data = load_tracking_data()
            last_hash = tracking_data.get(source_key, {}).get('last_hash')

            # æœ€æ–°ã®æƒ…å ±ã‚’æŠ½å‡º
            dates = re.findall(r'(20[2-9][0-9])', content)
            latest_year = max(dates) if dates else 'N/A'

            is_changed = last_hash != content_hash

            tracking_data[source_key] = {
                'name': NEWS_SOURCES[source_key]['name'],
                'url': url,
                'type': NEWS_SOURCES[source_key]['type'],
                'last_hash': content_hash,
                'latest_year': latest_year,
                'last_checked': datetime.now().isoformat(),
                'changed': is_changed
            }
            save_tracking_data(tracking_data)

            return is_changed, latest_year
        return False, 'Error'
    except Exception as e:
        print(f"Error checking {url}: {e}")
        return False, 'Error'

def generate_report(all_items):
    """ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    if not all_items:
        return ""

    report = ["ğŸ“° **Adobeè£½å“æœ€æ–°æƒ…å ±**\n"]
    report.append(f"ãƒã‚§ãƒƒã‚¯æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")

    release_notes = [item for item in all_items if item['type'] == 'release_notes']
    blogs = [item for item in all_items if item['type'] == 'blog']

    if release_notes:
        report.append("\nğŸ“‹ **ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆ:**")
        for item in release_notes:
            year = item.get('latest_year', 'N/A')
            report.append(f"- [{item['name']}]({item['url']}) (æœ€æ–°: {year})")

    if blogs:
        report.append("\nğŸ“ **ãƒ–ãƒ­ã‚°/ãƒ‹ãƒ¥ãƒ¼ã‚¹:**")
        for item in blogs:
            year = item.get('latest_year', 'N/A')
            report.append(f"- [{item['name']}]({item['url']}) (æœ€æ–°: {year})")

    return "\n".join(report)

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ” Adobeè£½å“ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯ä¸­...")

    for source_key, source_info in NEWS_SOURCES.items():
        print(f"Checking {source_info['name']}...")
        is_changed, latest_year = check_url_changes(source_key, source_info['url'])

        if is_changed:
            print(f"  â†’ å¤‰æ›´æ¤œå‡ºï¼æœ€æ–°å¹´: {latest_year}")
        else:
            print(f"  â†’ å¤‰æ›´ãªã— (æœ€æ–°å¹´: {latest_year})")

    # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯æ™‚åˆ»ã‚’ä¿å­˜
    save_last_check(datetime.now())

    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    tracking_data = load_tracking_data()
    all_items = list(tracking_data.values())

    report = generate_report(all_items)
    return report

if __name__ == "__main__":
    report = main()
    if report:
        print("\n" + "="*60)
        print(report)
        print("="*60)
